{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys, os, importlib\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from pandas import DataFrame\n",
    "from pandas import concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "if os.path.join('..','0_funcoes_base') not in sys.path:\n",
    "    sys.path.append(os.path.join('..','0_funcoes_base')) \n",
    "\n",
    "df_manipulator = importlib.import_module('df_manipulator')\n",
    "dt_manipulator = importlib.import_module('date_manipulator')\n",
    "plot_manipulator = importlib.import_module('plot_manipulator')\n",
    "file_manipulator = importlib.import_module('file_manipulator')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados de configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_config = {\n",
    "    'file': {\n",
    "        'ref_dir':'./out/',\n",
    "        'filename':'3_export_lunar_20200517.csv',\n",
    "        'delimiter': ';'\n",
    "    }\n",
    "}\n",
    "\n",
    "output_config = {\n",
    "    'file': {\n",
    "        'ref_dir': './out',\n",
    "        'delimiter':';',\n",
    "        'with_header': True,\n",
    "        'prefix':'4_'\n",
    "    },\n",
    "    'delimited_intervals': [5, 10, 20, 30, 40, 50],\n",
    "    'start_region': 3,\n",
    "    'end_region': 2,\n",
    "    'cusum_K': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_region_into_df(df, speed_bump_id, region_id, relative_start_region, relative_end_region, verbose=False):\n",
    "    _df = df.copy()\n",
    "\n",
    "    # Get indexes with speedbump\n",
    "    sb_indexes_by_id  = df_manipulator.get_speed_bumps_idx(_df, speed_bump_id=speed_bump_id)\n",
    "    speed_bumps       = sum(list(sb_indexes_by_id.values()), [])\n",
    "    speed_bumps       = [sb.to_pydatetime() for sb in speed_bumps]\n",
    "\n",
    "    available_min_idx = min(_df.index)\n",
    "    available_max_idx = max(_df.index)\n",
    "\n",
    "    region_by_speed_bump_timestamp = []\n",
    "\n",
    "    for sb_id in sb_indexes_by_id:\n",
    "        for sb_idx in sb_indexes_by_id[sb_id]:\n",
    "            if verbose:\n",
    "                print(f'Region {region_id}: [{sb_id}] {sb_idx} -> from {sb_idx-relative_start_region} to {sb_idx+relative_end_region}')\n",
    "\n",
    "            region_by_speed_bump_timestamp.extend([dt_manipulator.get_date_window(start_date=sb_idx-relative_start_region, end_date=sb_idx+relative_end_region, bound=(available_min_idx, available_max_idx))])\n",
    "\n",
    "    if len(region_by_speed_bump_timestamp) < 1:\n",
    "        return _df\n",
    "\n",
    "    #print(region_by_speed_bump_timestamp)\n",
    "    #return\n",
    "    # Rules\n",
    "    ## Region 0: without speedbump\n",
    "    ## Region 1: just one speedbump\n",
    "\n",
    "    final_region_timestamps = []\n",
    "    for region_timestamp in region_by_speed_bump_timestamp:\n",
    "        \n",
    "        # Apply region rules\n",
    "        if region_id == 0:\n",
    "            if len((set(speed_bumps) & set(region_timestamp))) > 0:\n",
    "                #print(f'Failed 1: {len((set(speed_bumps) & set(region_timestamp)))}')\n",
    "                continue\n",
    "        # elif region_id == 2:\n",
    "        #     if len((set(speed_bumps) & set(region_timestamp))) > 1:\n",
    "        #         #print(f'set(speed_bumps): {set(speed_bumps)}')\n",
    "        #         #print(f'\\n\\nset(region_timestamp): {set(region_timestamp)}')\n",
    "        #         print(f'\\n\\n/\\: {set(speed_bumps) & set(region_timestamp)}')\n",
    "        #         print(f'\\n\\nFailed 2: {len((set(speed_bumps) & set(region_timestamp)))}')\n",
    "        #         continue\n",
    "\n",
    "        final_region_timestamps.extend(region_timestamp)\n",
    "\n",
    "    final_region_timestamps = list(set(final_region_timestamps))\n",
    "\n",
    "    _df['region_id'][_df.index.isin(final_region_timestamps)] = region_id\n",
    "\n",
    "    return _df\n",
    "\n",
    "def cusum(x,mean=0,K=0):\n",
    "    \"\"\"\n",
    "    Tabular CUSUM per Montgomery,D. 1996 \"Introduction to Statistical Process Control\" p318\n",
    "    x    : series to analyze\n",
    "    mean : expected process mean\n",
    "    K    : reference value, allowance, slack value-- suggest K=1/2 of the shift to be detected.\n",
    "    Returns:\n",
    "    x  Original series\n",
    "    Cp positive CUSUM\n",
    "    Cm negative CUSUM\n",
    "    \"\"\"\n",
    "    Cp=(x*0).copy()\n",
    "    Cm=Cp.copy()\n",
    "    for ii in np.arange(len(x)):\n",
    "        if ii == 0:\n",
    "            Cp[ii]=x[ii]\n",
    "            Cm[ii]=x[ii]\n",
    "        else:\n",
    "            Cp[ii]=np.max([0,(x[ii]-mean-K)+Cp[ii-1]])\n",
    "            Cm[ii]=np.max([0,(mean-K)-x[ii]+Cm[ii-1]])\n",
    "    return({'x':x, 'Cp': Cp, 'Cm': Cm})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_manipulator.load_dataframe(input_config['file']['filename'], input_config['file']['ref_dir'], input_config['file']['delimiter'])\n",
    "df.timestamp = pd.to_datetime(df.timestamp)\n",
    "df_manipulator.set_index(df, 'timestamp', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                         speed_bump_id          y         z        lat  \\\ntimestamp                                                                \n2020-05-17 20:10:48.400              0   9.516205  1.573975 -22.921991   \n2020-05-17 20:10:48.500              0   9.516205  1.573975 -22.921991   \n2020-05-17 20:10:48.600              0  10.203339  1.291458 -22.921991   \n2020-05-17 20:10:48.700              0  10.203339  1.291458 -22.921991   \n2020-05-17 20:10:48.800              0   9.746048  1.806213 -22.921991   \n...                                ...        ...       ...        ...   \n2020-05-17 20:35:51.100              0   9.250443  1.770294 -22.925816   \n2020-05-17 20:35:51.200              0  10.105179  1.660172 -22.925816   \n2020-05-17 20:35:51.300              0   9.920822  2.608276 -22.925816   \n2020-05-17 20:35:51.400              0   9.523392  2.505325 -22.925816   \n2020-05-17 20:35:51.500              0   8.999054  2.871628 -22.925816   \n\n                               lng  \ntimestamp                           \n2020-05-17 20:10:48.400 -42.473372  \n2020-05-17 20:10:48.500 -42.473372  \n2020-05-17 20:10:48.600 -42.473372  \n2020-05-17 20:10:48.700 -42.473372  \n2020-05-17 20:10:48.800 -42.473372  \n...                            ...  \n2020-05-17 20:35:51.100 -42.484631  \n2020-05-17 20:35:51.200 -42.484631  \n2020-05-17 20:35:51.300 -42.484631  \n2020-05-17 20:35:51.400 -42.484631  \n2020-05-17 20:35:51.500 -42.484631  \n\n[14123 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speed_bump_id</th>\n      <th>y</th>\n      <th>z</th>\n      <th>lat</th>\n      <th>lng</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-05-17 20:10:48.400</th>\n      <td>0</td>\n      <td>9.516205</td>\n      <td>1.573975</td>\n      <td>-22.921991</td>\n      <td>-42.473372</td>\n    </tr>\n    <tr>\n      <th>2020-05-17 20:10:48.500</th>\n      <td>0</td>\n      <td>9.516205</td>\n      <td>1.573975</td>\n      <td>-22.921991</td>\n      <td>-42.473372</td>\n    </tr>\n    <tr>\n      <th>2020-05-17 20:10:48.600</th>\n      <td>0</td>\n      <td>10.203339</td>\n      <td>1.291458</td>\n      <td>-22.921991</td>\n      <td>-42.473372</td>\n    </tr>\n    <tr>\n      <th>2020-05-17 20:10:48.700</th>\n      <td>0</td>\n      <td>10.203339</td>\n      <td>1.291458</td>\n      <td>-22.921991</td>\n      <td>-42.473372</td>\n    </tr>\n    <tr>\n      <th>2020-05-17 20:10:48.800</th>\n      <td>0</td>\n      <td>9.746048</td>\n      <td>1.806213</td>\n      <td>-22.921991</td>\n      <td>-42.473372</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020-05-17 20:35:51.100</th>\n      <td>0</td>\n      <td>9.250443</td>\n      <td>1.770294</td>\n      <td>-22.925816</td>\n      <td>-42.484631</td>\n    </tr>\n    <tr>\n      <th>2020-05-17 20:35:51.200</th>\n      <td>0</td>\n      <td>10.105179</td>\n      <td>1.660172</td>\n      <td>-22.925816</td>\n      <td>-42.484631</td>\n    </tr>\n    <tr>\n      <th>2020-05-17 20:35:51.300</th>\n      <td>0</td>\n      <td>9.920822</td>\n      <td>2.608276</td>\n      <td>-22.925816</td>\n      <td>-42.484631</td>\n    </tr>\n    <tr>\n      <th>2020-05-17 20:35:51.400</th>\n      <td>0</td>\n      <td>9.523392</td>\n      <td>2.505325</td>\n      <td>-22.925816</td>\n      <td>-42.484631</td>\n    </tr>\n    <tr>\n      <th>2020-05-17 20:35:51.500</th>\n      <td>0</td>\n      <td>8.999054</td>\n      <td>2.871628</td>\n      <td>-22.925816</td>\n      <td>-42.484631</td>\n    </tr>\n  </tbody>\n</table>\n<p>14123 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adiciona regiões nos registros\n",
    "\n",
    "Seja *sb(t)* o instante que o veículo passou pelo quebra-mola.\n",
    "\n",
    "Serão classificadas **dois tipos** de regiões:\n",
    "\n",
    "- Região 1\n",
    "    - Momentos da direção aonde não consta quebra-molas próximos;\n",
    "    - Intervalo:  \\[sb(t-inf), sb(t-4)\\] V \\[sb(t+2), sb(t+inf)\\]\n",
    "- Região 2\n",
    "    - Momento que precedem quebra-mola;\n",
    "    - Inclui a ação do motorista frear para quebra-mola, passar pelo mesmo e acelerar;\n",
    "    - Intervalo:  \\[sb(t-4), sb(t+2)\\]\n",
    "\n",
    "\n",
    "**Obs:** sb(t-x), aonde x possui unidade em segundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    14078\n1       45\nName: speed_bump_id, dtype: int64"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df.speed_bump_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "df_out = df.copy()\n",
    "df_out['region_id'] = 0\n",
    "\n",
    "df_out = map_region_into_df(df_out, speed_bump_id=1, region_id=1, relative_start_region=pd.Timedelta(output_config['start_region'], 's'), relative_end_region=pd.Timedelta(output_config['end_region'], 's'), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    12105\n1     2018\nName: region_id, dtype: int64"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df_out.region_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adiciona normalização, média móvel, variância e diff do eixo Z e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['z-norm'] = (df_out['z'] - df_out['z'].mean())/df_out['z'].std()\n",
    "df_out['y-norm'] = (df_out['y'] - df_out['y'].mean())/df_out['y'].std()\n",
    "\n",
    "for i in output_config['delimited_intervals']:    \n",
    "    df_out[f'z-diff_{str(i)}'] = df_out['z-norm'].diff(periods=i)\n",
    "    df_out[f'z-mean_{str(i)}'] = df_out['z-norm'].rolling(i).mean()\n",
    "    df_out[f'z-std_{str(i)}']  = df_out['z-norm'].rolling(i).std()\n",
    "    \n",
    "    if i == 5 or i == 10:\n",
    "        df_out[f'z-corr-std_{str(i)}'] = df_out['z-norm'].rolling(i).corr(df_out[f'z-std_{str(i)}'])\n",
    "        df_out[f'y-corr-z-mean_{str(i)}'] = df_out['y-norm'].rolling(i).corr(df_out[f'z-mean_{str(i)}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adiciona CuSum features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cusum(df_out['z-norm'].values, mean=df_out['z-norm'].values.mean(), K = output_config['cusum_K'])\n",
    "\n",
    "df_out['cp'] = result['Cp']\n",
    "df_out['cm'] = result['Cm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva o dataframe de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "O arquivo ./out/4_export_lunar_20200517.csv foi gerado!\n"
    }
   ],
   "source": [
    "out_filename = file_manipulator.get_out_filename(output_config['file']['prefix'], output_config['file']['ref_dir'], input_config['file']['filename'])\n",
    "\n",
    "df_out.to_csv(out_filename, sep=output_config['file']['delimiter'], header=output_config['file']['with_header'])\n",
    "\n",
    "print(f'O arquivo {out_filename} foi gerado!')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitvenvvenv15842a2001b14e7c9614d80f05b24238",
   "display_name": "Python 3.6.9 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}