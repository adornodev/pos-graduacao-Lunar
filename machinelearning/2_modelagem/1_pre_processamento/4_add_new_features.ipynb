{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys, os, importlib\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "if os.path.join('..','0_funcoes_base') not in sys.path:\n",
    "    sys.path.append(os.path.join('..','0_funcoes_base')) \n",
    "\n",
    "df_manipulator = importlib.import_module('df_manipulator')\n",
    "dt_manipulator = importlib.import_module('date_manipulator')\n",
    "plot_manipulator = importlib.import_module('plot_manipulator')\n",
    "file_manipulator = importlib.import_module('file_manipulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados de configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_config = {\n",
    "    'file': {\n",
    "        'ref_dir':'./out/',\n",
    "        'filename':'3_export_lunar_20200517_20200620.csv',\n",
    "        'delimiter': ';'\n",
    "    }\n",
    "}\n",
    "\n",
    "output_config = {\n",
    "    'file': {\n",
    "        'ref_dir': './out',\n",
    "        'delimiter':';',\n",
    "        'with_header': True,\n",
    "        'prefix':'4_'\n",
    "    },\n",
    "    'delimited_intervals': [5, 10, 20, 30, 40, 50],\n",
    "    'start_region': 3,\n",
    "    'end_region': 2,\n",
    "    'cusum_K': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_region_into_df(df, speed_bump_id, region_id, relative_start_region, relative_end_region, verbose=False):\n",
    "    _df = df.copy()\n",
    "\n",
    "    # Get indexes with speedbump\n",
    "    sb_indexes_by_id  = df_manipulator.get_speed_bumps_idx(_df, speed_bump_id=speed_bump_id)\n",
    "    speed_bumps       = sum(list(sb_indexes_by_id.values()), [])\n",
    "    speed_bumps       = [sb.to_pydatetime() for sb in speed_bumps]\n",
    "\n",
    "    available_min_idx = min(_df.index)\n",
    "    available_max_idx = max(_df.index)\n",
    "\n",
    "    region_by_speed_bump_timestamp = []\n",
    "\n",
    "    for sb_id in sb_indexes_by_id:\n",
    "        for sb_idx in sb_indexes_by_id[sb_id]:\n",
    "            if verbose:\n",
    "                print(f'Region {region_id}: [{sb_id}] {sb_idx} -> from {sb_idx-relative_start_region} to {sb_idx+relative_end_region}')\n",
    "\n",
    "            region_by_speed_bump_timestamp.extend([dt_manipulator.get_date_window(start_date=sb_idx-relative_start_region, end_date=sb_idx+relative_end_region, bound=(available_min_idx, available_max_idx))])\n",
    "\n",
    "    if len(region_by_speed_bump_timestamp) < 1:\n",
    "        return _df\n",
    "\n",
    "    #print(region_by_speed_bump_timestamp)\n",
    "    #return\n",
    "    # Rules\n",
    "    ## Region 0: without speedbump\n",
    "    ## Region 1: just one speedbump\n",
    "\n",
    "    final_region_timestamps = []\n",
    "    for region_timestamp in region_by_speed_bump_timestamp:\n",
    "        \n",
    "        # Apply region rules\n",
    "        if region_id == 0:\n",
    "            if len((set(speed_bumps) & set(region_timestamp))) > 0:\n",
    "                #print(f'Failed 1: {len((set(speed_bumps) & set(region_timestamp)))}')\n",
    "                continue\n",
    "        # elif region_id == 2:\n",
    "        #     if len((set(speed_bumps) & set(region_timestamp))) > 1:\n",
    "        #         #print(f'set(speed_bumps): {set(speed_bumps)}')\n",
    "        #         #print(f'\\n\\nset(region_timestamp): {set(region_timestamp)}')\n",
    "        #         print(f'\\n\\n/\\: {set(speed_bumps) & set(region_timestamp)}')\n",
    "        #         print(f'\\n\\nFailed 2: {len((set(speed_bumps) & set(region_timestamp)))}')\n",
    "        #         continue\n",
    "\n",
    "        final_region_timestamps.extend(region_timestamp)\n",
    "\n",
    "    final_region_timestamps = list(set(final_region_timestamps))\n",
    "\n",
    "    _df['region_id'][_df.index.isin(final_region_timestamps)] = region_id\n",
    "\n",
    "    return _df\n",
    "\n",
    "def cusum(x,mean=0,K=0):\n",
    "    \"\"\"\n",
    "    Tabular CUSUM per Montgomery,D. 1996 \"Introduction to Statistical Process Control\" p318\n",
    "    x    : series to analyze\n",
    "    mean : expected process mean\n",
    "    K    : reference value, allowance, slack value-- suggest K=1/2 of the shift to be detected.\n",
    "    Returns:\n",
    "    x  Original series\n",
    "    Cp positive CUSUM\n",
    "    Cm negative CUSUM\n",
    "    \"\"\"\n",
    "    Cp=(x*0).copy()\n",
    "    Cm=Cp.copy()\n",
    "    for ii in np.arange(len(x)):\n",
    "        if ii == 0:\n",
    "            Cp[ii]=x[ii]\n",
    "            Cm[ii]=x[ii]\n",
    "        else:\n",
    "            Cp[ii]=np.max([0,(x[ii]-mean-K)+Cp[ii-1]])\n",
    "            Cm[ii]=np.max([0,(mean-K)-x[ii]+Cm[ii-1]])\n",
    "    return({'x':x, 'Cp': Cp, 'Cm': Cm})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrega dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                         speed_bump_id          y         z        lat  \\\ntimestamp                                                                \n2020-05-17 20:14:32.800              0   8.838654  3.714386 -22.919592   \n2020-05-17 20:14:32.900              0  10.248825  3.108658 -22.919592   \n2020-05-17 20:14:33.000              0  10.842590  2.215622 -22.919592   \n2020-05-17 20:14:33.100              0   9.702957  2.493347 -22.919592   \n2020-05-17 20:14:33.200              0   9.702957  2.493347 -22.919592   \n...                                ...        ...       ...        ...   \n2020-06-20 14:41:23.800              0   8.189819  6.620956 -22.871247   \n2020-06-20 14:41:23.900              0   8.189819  6.620956 -22.871247   \n2020-06-20 14:41:24.000              0   8.970322  5.715942 -22.871481   \n2020-06-20 14:41:24.100              0  11.125107  4.638550 -22.871481   \n2020-06-20 14:41:24.200              0   9.930405  3.197250 -22.871481   \n\n                               lng  \ntimestamp                           \n2020-05-17 20:14:32.800 -42.473961  \n2020-05-17 20:14:32.900 -42.473961  \n2020-05-17 20:14:33.000 -42.473961  \n2020-05-17 20:14:33.100 -42.473961  \n2020-05-17 20:14:33.200 -42.473961  \n...                            ...  \n2020-06-20 14:41:23.800 -42.340474  \n2020-06-20 14:41:23.900 -42.340474  \n2020-06-20 14:41:24.000 -42.340609  \n2020-06-20 14:41:24.100 -42.340609  \n2020-06-20 14:41:24.200 -42.340609  \n\n[20436 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speed_bump_id</th>\n      <th>y</th>\n      <th>z</th>\n      <th>lat</th>\n      <th>lng</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-05-17 20:14:32.800</th>\n      <td>0</td>\n      <td>8.838654</td>\n      <td>3.714386</td>\n      <td>-22.919592</td>\n      <td>-42.473961</td>\n    </tr>\n    <tr>\n      <th>2020-05-17 20:14:32.900</th>\n      <td>0</td>\n      <td>10.248825</td>\n      <td>3.108658</td>\n      <td>-22.919592</td>\n      <td>-42.473961</td>\n    </tr>\n    <tr>\n      <th>2020-05-17 20:14:33.000</th>\n      <td>0</td>\n      <td>10.842590</td>\n      <td>2.215622</td>\n      <td>-22.919592</td>\n      <td>-42.473961</td>\n    </tr>\n    <tr>\n      <th>2020-05-17 20:14:33.100</th>\n      <td>0</td>\n      <td>9.702957</td>\n      <td>2.493347</td>\n      <td>-22.919592</td>\n      <td>-42.473961</td>\n    </tr>\n    <tr>\n      <th>2020-05-17 20:14:33.200</th>\n      <td>0</td>\n      <td>9.702957</td>\n      <td>2.493347</td>\n      <td>-22.919592</td>\n      <td>-42.473961</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020-06-20 14:41:23.800</th>\n      <td>0</td>\n      <td>8.189819</td>\n      <td>6.620956</td>\n      <td>-22.871247</td>\n      <td>-42.340474</td>\n    </tr>\n    <tr>\n      <th>2020-06-20 14:41:23.900</th>\n      <td>0</td>\n      <td>8.189819</td>\n      <td>6.620956</td>\n      <td>-22.871247</td>\n      <td>-42.340474</td>\n    </tr>\n    <tr>\n      <th>2020-06-20 14:41:24.000</th>\n      <td>0</td>\n      <td>8.970322</td>\n      <td>5.715942</td>\n      <td>-22.871481</td>\n      <td>-42.340609</td>\n    </tr>\n    <tr>\n      <th>2020-06-20 14:41:24.100</th>\n      <td>0</td>\n      <td>11.125107</td>\n      <td>4.638550</td>\n      <td>-22.871481</td>\n      <td>-42.340609</td>\n    </tr>\n    <tr>\n      <th>2020-06-20 14:41:24.200</th>\n      <td>0</td>\n      <td>9.930405</td>\n      <td>3.197250</td>\n      <td>-22.871481</td>\n      <td>-42.340609</td>\n    </tr>\n  </tbody>\n</table>\n<p>20436 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df = df_manipulator.load_dataframes(input_config['file']['filename'], input_config['file']['ref_dir'], input_config['file']['delimiter'])\n",
    "df.timestamp = pd.to_datetime(df.timestamp)\n",
    "df_manipulator.set_index(df, 'timestamp', True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adiciona regiões nos registros\n",
    "\n",
    "Seja *sb(t)* o instante que o veículo passou pelo quebra-mola.\n",
    "\n",
    "Serão classificadas **dois tipos** de regiões:\n",
    "\n",
    "- Região 1\n",
    "    - Momentos da direção aonde não consta quebra-molas próximos;\n",
    "    - Intervalo:  \\[sb(t-inf), sb(t-3)\\] V \\[sb(t+3), sb(t+inf)\\]\n",
    "- Região 2\n",
    "    - Momento que precedem quebra-mola;\n",
    "    - Inclui a ação do motorista frear para quebra-mola, passar pelo mesmo e acelerar;\n",
    "    - Intervalo:  \\[sb(t-3), sb(t+3)\\]\n",
    "\n",
    "\n",
    "**Obs:** sb(t-x), aonde x possui unidade em segundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    20348\n1       88\nName: speed_bump_id, dtype: int64"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.speed_bump_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "df_out = df.copy()\n",
    "df_out['region_id'] = 0\n",
    "\n",
    "df_out = map_region_into_df(df_out, speed_bump_id=1, region_id=1, relative_start_region=pd.Timedelta(output_config['start_region'], 's'), relative_end_region=pd.Timedelta(output_config['end_region'], 's'), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    16372\n1     4064\nName: region_id, dtype: int64"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_out.region_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adiciona normalização, média móvel, variância e diff do eixo Z e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['z-norm'] = (df_out['z'] - df_out['z'].mean())/df_out['z'].std()\n",
    "df_out['y-norm'] = (df_out['y'] - df_out['y'].mean())/df_out['y'].std()\n",
    "\n",
    "for i in output_config['delimited_intervals']:    \n",
    "    df_out[f'z-diff_{str(i)}'] = df_out['z-norm'].diff(periods=i)\n",
    "    df_out[f'z-mean_{str(i)}'] = df_out['z-norm'].rolling(i).mean()\n",
    "    df_out[f'z-std_{str(i)}']  = df_out['z-norm'].rolling(i).std()\n",
    "    \n",
    "    if i == 5 or i == 10:\n",
    "        df_out[f'z-corr-std_{str(i)}'] = df_out['z-norm'].rolling(i).corr(df_out[f'z-std_{str(i)}'])\n",
    "        df_out[f'y-corr-z-mean_{str(i)}'] = df_out['y-norm'].rolling(i).corr(df_out[f'z-mean_{str(i)}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adiciona CuSum features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cusum(df_out['z-norm'].values, mean=df_out['z-norm'].values.mean(), K = output_config['cusum_K'])\n",
    "\n",
    "df_out['cp'] = result['Cp']\n",
    "df_out['cm'] = result['Cm']\n",
    "\n",
    "df_out['cp-norm'] = (df_out['cp'] - df_out['cp'].mean())/df_out['cp'].std()\n",
    "df_out['cm-norm'] = (df_out['cm'] - df_out['cm'].mean())/df_out['cm'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adiciona feature de distância dos pontos até a próxima região 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros(len(df_out['region_id']))\n",
    "\n",
    "res[0] = df_out['region_id'].iloc[0]\n",
    "\n",
    "count = 1\n",
    "for idx, val in df_out['region_id'].iloc[1:].iteritems():\n",
    "    if val == 0:\n",
    "        res[count] = res[count-1] + 1\n",
    "    elif val == 1:\n",
    "        res[count] = 0\n",
    "    count +=1\n",
    "\n",
    "df_out['region_1_distance'] = res.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adiciona feature que informa a contagem dos eventos da região 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros(len(df_out['region_id']))\n",
    "\n",
    "res[0] = df_out['region_id'].iloc[0]\n",
    "\n",
    "count = 0 if res[0] == 0 else 1\n",
    "i = 1\n",
    "for idx, val in df_out['region_id'].iloc[1:].iteritems():\n",
    "    if val == 0:\n",
    "        res[i] = 0\n",
    "    elif val == 1:\n",
    "        if res[i-1] == 0:\n",
    "            count += 1\n",
    "        res[i] = count\n",
    "    i +=1\n",
    "\n",
    "df_out['region_1_counter'] = res.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    16322\n1     4064\nName: region_id, dtype: int64"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df_out['region_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    20298\n1       88\nName: speed_bump_id, dtype: int64"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df_out['speed_bump_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salva o dataframe de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "O arquivo ./out/4_export_lunar_20200517_20200620.csv foi gerado!\n"
    }
   ],
   "source": [
    "out_filename = file_manipulator.get_out_filename(output_config['file']['prefix'], output_config['file']['ref_dir'], input_config['file']['filename'])\n",
    "\n",
    "df_out.to_csv(out_filename, sep=output_config['file']['delimiter'], header=output_config['file']['with_header'])\n",
    "\n",
    "print(f'O arquivo {out_filename} foi gerado!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitvenvvenv15842a2001b14e7c9614d80f05b24238",
   "display_name": "Python 3.6.9 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}